{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get,codes\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import lzma\n",
    "import urllib.parse\n",
    "import numpy\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://free-proxy-list.net/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(proxy.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td>217.182.120.162</td>,\n",
       " <td>1080</td>,\n",
       " <td>FR</td>,\n",
       " <td class=\"hm\">France</td>,\n",
       " <td>elite proxy</td>,\n",
       " <td class=\"hm\">no</td>,\n",
       " <td class=\"hx\">yes</td>,\n",
       " <td class=\"hm\">24 seconds ago</td>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"tbody\")[0].find_all(\"tr\")[0].find_all(\"td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_addresses = []\n",
    "for en in soup.find_all(\"tbody\")[0].find_all(\"tr\"):\n",
    "    parsed_entry = en.find_all(\"td\")\n",
    "    if(parsed_entry[4].text == \"elite proxy\"):\n",
    "        ip_addresses.append(parsed_entry[0].text+\":\"+parsed_entry[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proxy mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "base_url = \"https://www.planespotters.net/\"\n",
    "url = \"airlines/country\"\n",
    "base_path = os.path.join(\".\", \"data\",\"planespotter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:21.0) Gecko/20130331 Firefox/21.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ua.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_or_retrive(url_extension: str) -> (get, bool):\n",
    "    \"\"\" For fetching content of webpage from \"https://www.planespotters.net/\".\n",
    "    Will store local version of the page once fetched. New calls to this function\n",
    "    will not create a new online requests\n",
    "    \n",
    "    :returns: tuple. first element is the request fetwched. The second is true is data found locally. \n",
    "    \"\"\"\n",
    "    \n",
    "    folder_path = os.path.join(base_path, *url_extension.split('/')[:-1])\n",
    "    file_path = os.path.join(folder_path, (url_extension.split('/')[-1]+\".html.xz\"))\n",
    "    if(os.path.isfile(file_path)):\n",
    "        with lzma.open(file_path, \"rb\") as wiki_file:\n",
    "            print(\"loading data from hard drive\")\n",
    "            r = pickle.load(wiki_file)\n",
    "            return r, True\n",
    "    else:\n",
    "        try:\n",
    "            url =  urllib.parse.urljoin(base_url, url_extension)\n",
    "            headers = {'User-Agent': ua.random}\n",
    "            proxy_index = numpy.random.randint(0, len(ip_addresses) - 1)\n",
    "            proxy = {\"http\": ip_addresses[proxy_index], \"https\": ip_addresses[proxy_index]}\n",
    "            r = get(url, headers=headers) #faking the fact that we are not a bot.\n",
    "            print(\"fetching online wikipedia page\")\n",
    "            print(r.status_code)\n",
    "            if(r.status_code == codes.ok):\n",
    "                os.makedirs(folder_path, exist_ok=True)\n",
    "                with lzma.open(file_path, \"wb\") as wiki_file:\n",
    "                    pickle.dump(r, wiki_file)\n",
    "            else:\n",
    "                raise Exception(\"Cannot find local version of data and website not responding with 200.\")\n",
    "        except:\n",
    "            raise Exception(\"Cannot access the internet\")\n",
    "            \n",
    "        return r, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching online wikipedia page\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_or_retrive(\"country/operators/Albania\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "country = pd.read_csv(os.path.join(\".\", \"data\",\"iso3166-countries-regional-codes.csv.xz\"))\n",
    "\n",
    "len(country[country.region == \"Europe\"].name.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from hard drive\n"
     ]
    }
   ],
   "source": [
    "countries_data = fetch_or_retrive(\"airlines/country\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_country = {}\n",
    "soup = BeautifulSoup(countries_data.text, 'lxml')\n",
    "coutry_list_raw = soup.find('div', attrs={'id': 'CountryList'})\n",
    "for c in coutry_list_raw.find_all('a'):\n",
    "    dict_country[c.text] = c.get('href')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "dict_european_country = {}\n",
    "for d in dict_country.copy().items():\n",
    "    if(d[0] in (country[country.region == \"Europe\"].name.values)):\n",
    "        dict_european_country[d[0]] = d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Albania': 'country/operators/Albania',\n",
       " 'Andorra': 'country/operators/Andorra',\n",
       " 'Austria': 'country/operators/Austria',\n",
       " 'Belarus': 'country/operators/Belarus',\n",
       " 'Belgium': 'country/operators/Belgium',\n",
       " 'Bulgaria': 'country/operators/Bulgaria',\n",
       " 'Croatia': 'country/operators/Croatia',\n",
       " 'Denmark': 'country/operators/Denmark',\n",
       " 'Estonia': 'country/operators/Estonia',\n",
       " 'Faroe Islands': 'country/operators/Faroe-Islands',\n",
       " 'Finland': 'country/operators/Finland',\n",
       " 'France': 'country/operators/France',\n",
       " 'Germany': 'country/operators/Germany',\n",
       " 'Gibraltar': 'country/operators/Gibraltar',\n",
       " 'Greece': 'country/operators/Greece',\n",
       " 'Guernsey': 'country/operators/Guernsey',\n",
       " 'Hungary': 'country/operators/Hungary',\n",
       " 'Iceland': 'country/operators/Iceland',\n",
       " 'Ireland': 'country/operators/Ireland',\n",
       " 'Isle of Man': 'country/operators/Isle-of-Man',\n",
       " 'Italy': 'country/operators/Italy',\n",
       " 'Jersey': 'country/operators/Jersey',\n",
       " 'Latvia': 'country/operators/Latvia',\n",
       " 'Liechtenstein': 'country/operators/Liechtenstein',\n",
       " 'Lithuania': 'country/operators/Lithuania',\n",
       " 'Luxembourg': 'country/operators/Luxembourg',\n",
       " 'Malta': 'country/operators/Malta',\n",
       " 'Monaco': 'country/operators/Monaco',\n",
       " 'Montenegro': 'country/operators/Montenegro',\n",
       " 'Netherlands': 'country/operators/Netherlands',\n",
       " 'North Macedonia': 'country/operators/Macedonia-The-Former-Yugoslav-Republic-Of',\n",
       " 'Norway': 'country/operators/Norway',\n",
       " 'Poland': 'country/operators/Poland',\n",
       " 'Portugal': 'country/operators/Portugal',\n",
       " 'Romania': 'country/operators/Romania',\n",
       " 'Russian Federation': 'country/operators/Russian-Federation',\n",
       " 'San Marino': 'country/operators/San-Marino',\n",
       " 'Serbia': 'country/operators/Serbia',\n",
       " 'Slovakia': 'country/operators/Slovakia',\n",
       " 'Slovenia': 'country/operators/Slovenia',\n",
       " 'Spain': 'country/operators/Spain',\n",
       " 'Sweden': 'country/operators/Sweden',\n",
       " 'Switzerland': 'country/operators/Switzerland',\n",
       " 'Ukraine': 'country/operators/Ukraine'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_european_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_european_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albania country/operators/Albania\n",
      "loading data from hard drive\n",
      "Andorra country/operators/Andorra\n",
      "fetching online wikipedia page\n",
      "200\n",
      "Austria country/operators/Austria\n",
      "fetching online wikipedia page\n",
      "200\n",
      "Belarus country/operators/Belarus\n",
      "fetching online wikipedia page\n",
      "200\n",
      "Belgium country/operators/Belgium\n",
      "fetching online wikipedia page\n",
      "200\n",
      "Bulgaria country/operators/Bulgaria\n",
      "fetching online wikipedia page\n",
      "200\n",
      "Croatia country/operators/Croatia\n",
      "fetching online wikipedia page\n",
      "200\n",
      "Denmark country/operators/Denmark\n",
      "fetching online wikipedia page\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_response = {}\n",
    "for country, url in dict_european_country.items():\n",
    "    print(country + \" \" + url)\n",
    "    dict_response[country], found_on_disk = fetch_or_retrive(url)\n",
    "    if(not found_on_disk):\n",
    "        time.sleep(60 + numpy.random.randint(0,40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for table in soup.find_all(\"table\"):\n",
    "    table_headers = []\n",
    "    dict_plane = {}\n",
    "    for header in table.find_all(\"th\"):\n",
    "        head = header.text.replace(\"\\n\", \"\")\n",
    "        table_headers.append(head)\n",
    "        dict_plane[head] = []\n",
    "    for line in table.find_all(\"tr\"):\n",
    "        for i, elem in enumerate(line.find_all('td')):\n",
    "            dict_plane[table_headers[i]].append(elem.text.replace(\"\\n\", \"\"))\n",
    "    dataframes.append(dict_plane)\n",
    "    \n",
    "dataframes = dataframes[:-1] #We don't want the private jets\n",
    "print(\"There are \" + str(len(dataframes))+ \" dataframes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
